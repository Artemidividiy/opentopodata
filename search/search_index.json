{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Open Topo Data Open Topo Data is an elevation API. Host your own or use the free public API . Open Topo Data is a REST API server for your elevation data. curl https://api.opentopodata.org/v1/test-dataset?locations=56,123 { \"results\" : [{ \"elevation\" : 815.0 , \"location\" : { \"lat\" : 56.0 , \"lng\" : 123.0 } }], \"status\" : \"OK\" } You can self-host with your own dataset or use the free public API which is configured with a number of open elevation datasets. The API is largely compatible with the Google Maps Elevation API. Host your own Install docker and git then run: git clone https://github.com/ajnisbet/opentopodata.git cd opentopodata make build make run This will start an Open Topo Data server on http://localhost:5000/ . Open Topo Data supports a wide range of raster file formats and tiling schemes, including most of those used by popular open elevation datasets. See the server docs for more about configuration and adding datasets. Usage Open Topo Data has a single endpoint: a point query endpoint that returns the elevation at a single point or a series of points. curl https://api.opentopodata.org/v1/test-dataset?locations=56.35,123.90 { \"results\" : [{ \"elevation\" : 815.0 , \"location\" : { \"lat\" : 56.0 , \"lng\" : 123.0 } }], \"status\" : \"OK\" } The interpolation algorithm used can be configured as a request parameter, and locations can also be provided in Google Polyline format. See the API docs for more about request and response formats. Public API I'm hosting a free public API at api.opentopodata.org . To keep the public API sustainable some limitations are applied. Max 100 locations per request. Max 1 call per second. Max 1000 calls per day. The following datasets are available on the public API, with elevation shown for downtown Denver, Colorado (39.7471, -104.9963). Dataset name Resolution Extent Source API link (Denver, CO) nzdem8m 8 m New Zealand. LINZ Not in dataset bounds ned10m ~10 m Continental USA, Hawaii, parts of Alaska. USGS 1590 m eudem25m 25 m Europe. EEA Not in dataset bounds mapzen ~30 m Global, inluding bathymetry. Mapzen 1590 m aster30m ~30 m Global. NASA 1591 m srtm30m ~30 m Latitudes -60 to 60. USGS 1604 m srtm90m ~90 m Latitudes -60 to 60. USGS 1603 m etopo1 ~1.8 km Global, including bathymetry and ice surface elevation near poles. NOAA 1596 m gebco2020 ~450m Global bathymetry and land elevation. GEBCO 1603 m emod2018 ~100m Bathymetry for ocean and sea in Europe. EMODnet Not in dataset bounds See the API docs for more about request formats and parameters. Support Want help getting Open Topo Data running? Send me an email at andrew@opentopodata.org .","title":"Introduction"},{"location":"#host-your-own","text":"Install docker and git then run: git clone https://github.com/ajnisbet/opentopodata.git cd opentopodata make build make run This will start an Open Topo Data server on http://localhost:5000/ . Open Topo Data supports a wide range of raster file formats and tiling schemes, including most of those used by popular open elevation datasets. See the server docs for more about configuration and adding datasets.","title":"Host your own"},{"location":"#usage","text":"Open Topo Data has a single endpoint: a point query endpoint that returns the elevation at a single point or a series of points. curl https://api.opentopodata.org/v1/test-dataset?locations=56.35,123.90 { \"results\" : [{ \"elevation\" : 815.0 , \"location\" : { \"lat\" : 56.0 , \"lng\" : 123.0 } }], \"status\" : \"OK\" } The interpolation algorithm used can be configured as a request parameter, and locations can also be provided in Google Polyline format. See the API docs for more about request and response formats.","title":"Usage"},{"location":"#public-api","text":"I'm hosting a free public API at api.opentopodata.org . To keep the public API sustainable some limitations are applied. Max 100 locations per request. Max 1 call per second. Max 1000 calls per day. The following datasets are available on the public API, with elevation shown for downtown Denver, Colorado (39.7471, -104.9963). Dataset name Resolution Extent Source API link (Denver, CO) nzdem8m 8 m New Zealand. LINZ Not in dataset bounds ned10m ~10 m Continental USA, Hawaii, parts of Alaska. USGS 1590 m eudem25m 25 m Europe. EEA Not in dataset bounds mapzen ~30 m Global, inluding bathymetry. Mapzen 1590 m aster30m ~30 m Global. NASA 1591 m srtm30m ~30 m Latitudes -60 to 60. USGS 1604 m srtm90m ~90 m Latitudes -60 to 60. USGS 1603 m etopo1 ~1.8 km Global, including bathymetry and ice surface elevation near poles. NOAA 1596 m gebco2020 ~450m Global bathymetry and land elevation. GEBCO 1603 m emod2018 ~100m Bathymetry for ocean and sea in Europe. EMODnet Not in dataset bounds See the API docs for more about request formats and parameters.","title":"Public API"},{"location":"#support","text":"Want help getting Open Topo Data running? Send me an email at andrew@opentopodata.org .","title":"Support"},{"location":"api/","text":"API Documentation A public API is available for testing at api.opentopodata.org . GET /v1/<dataset_name> Reads the elevation from a given dataset. The dataset must match one of the options in config.yaml . Latitudes and longitudes should be in EPSG:4326 (also known as WGS-84 format), they will be converted internally to whatever the dataset uses. Args locations : Required. Either latitutde,longitude pairs, each separated by a pipe character | . Example: locations=12.5,160.2|-10.6,130 . Google polyline format . Example: locations=gfo}EtohhU . interpolation : How to interpolate between the points in the dataset. Options: nearest , bilinear , cubic . Default: bilinear . Response A json object, compatible with the Google Maps Elevation API. status : Will be OK for a successful request, INVALID_REQUEST for an input (4xx) error, and SERVER_ERROR for anything else (5xx). Required. error : Description of what went wrong, when status isn't OK . results : List of elevations for each location, in same order as input. Only provided for OK status. results[].elevation : Elevation, using units and datum from the dataset. May be NaN if the dataset has a NODATA value at the given location. May be null if the given location is outside the dataset bounds. results[].location.lat : Latitude as parsed by Open Topo Data. results[].location.lng : Longitude as parsed by Open Topo Data. Some notes about the elevation value: If the raster has an integer data type, the interpolated elevation will be rounded to the nearest integer. This is a limitation of rasterio/gdal. If the raster has a NODATA value at the request location, Open Topo Data will return NaN . If the request location isn't covered by any raster in the dataset, Open Topo Data will return null . Example GET api.opentopodata.org/v1/srtm90m?locations=-43.5,172.5|27.6,1.98&interpolation=cubic { \"results\" : [ { \"elevation\" : 45 , \"location\" : { \"lat\" : -43.5 , \"lng\" : 172.5 } }, { \"elevation\" : 402 , \"location\" : { \"lat\" : 27.6 , \"lng\" : 1.98 } } ], \"status\" : \"OK\" } GET /health Healthcheck endpoint, for use with load balancing or monitoring. Response A json object. status : Will be OK if the server is running and the config file can be loaded. Otherwise the value will be SERVER_ERROR . The status code is 200 if healthy, otherwise 500. Example GET api.opentopodata.org/health { \"status\": \"OK\" }","title":"API docs"},{"location":"api/#api-documentation","text":"A public API is available for testing at api.opentopodata.org .","title":"API Documentation"},{"location":"api/#get-v1ltdataset_namegt","text":"Reads the elevation from a given dataset. The dataset must match one of the options in config.yaml . Latitudes and longitudes should be in EPSG:4326 (also known as WGS-84 format), they will be converted internally to whatever the dataset uses.","title":"GET /v1/&lt;dataset_name&gt;"},{"location":"api/#args","text":"locations : Required. Either latitutde,longitude pairs, each separated by a pipe character | . Example: locations=12.5,160.2|-10.6,130 . Google polyline format . Example: locations=gfo}EtohhU . interpolation : How to interpolate between the points in the dataset. Options: nearest , bilinear , cubic . Default: bilinear .","title":"Args"},{"location":"api/#response","text":"A json object, compatible with the Google Maps Elevation API. status : Will be OK for a successful request, INVALID_REQUEST for an input (4xx) error, and SERVER_ERROR for anything else (5xx). Required. error : Description of what went wrong, when status isn't OK . results : List of elevations for each location, in same order as input. Only provided for OK status. results[].elevation : Elevation, using units and datum from the dataset. May be NaN if the dataset has a NODATA value at the given location. May be null if the given location is outside the dataset bounds. results[].location.lat : Latitude as parsed by Open Topo Data. results[].location.lng : Longitude as parsed by Open Topo Data. Some notes about the elevation value: If the raster has an integer data type, the interpolated elevation will be rounded to the nearest integer. This is a limitation of rasterio/gdal. If the raster has a NODATA value at the request location, Open Topo Data will return NaN . If the request location isn't covered by any raster in the dataset, Open Topo Data will return null .","title":"Response"},{"location":"api/#example","text":"GET api.opentopodata.org/v1/srtm90m?locations=-43.5,172.5|27.6,1.98&interpolation=cubic { \"results\" : [ { \"elevation\" : 45 , \"location\" : { \"lat\" : -43.5 , \"lng\" : 172.5 } }, { \"elevation\" : 402 , \"location\" : { \"lat\" : 27.6 , \"lng\" : 1.98 } } ], \"status\" : \"OK\" }","title":"Example"},{"location":"api/#get-health","text":"Healthcheck endpoint, for use with load balancing or monitoring.","title":"GET /health"},{"location":"api/#response_1","text":"A json object. status : Will be OK if the server is running and the config file can be loaded. Otherwise the value will be SERVER_ERROR . The status code is 200 if healthy, otherwise 500.","title":"Response"},{"location":"api/#example_1","text":"GET api.opentopodata.org/health { \"status\": \"OK\" }","title":"Example"},{"location":"changelog/","text":"Release Notes This is a list of changes to Open Topo Data between each release. Version 1.3.0 (4 Sep 2020) Added /health endpoint. Version 1.2.4 (8 Aug 2020) Support for more raster filename formats, as raised in issue #8 . Version 1.2.3 (31 July 2020) Minor documentation fixes and dependency updates. Version 1.2.2 (2 July 2020) Documentation fixes. I'm now using pip-tools to manage python dependencies, and I'm really liking it. Exact dependency versions are now pinned, but it's easy to update them to the latest version. Updated dependencies. Version 1.2.1 (22 May 2020) Improved documentation, plus some bug fixes: Fix floating-point precision issue that was breaking requests on dataset boundaries. Ignore common non-raster files. Version 1.2.0 (10 May 2020) Added a bunch of new datasets to the public API: GEBCO bathymetry. EMOD bathymetry. NZ 8m DEM. Mapzen 30m DEM. Version 1.1.0 (25 April 2020) Added this changelog! Pushing to master now means a release with a changelog entry. Added VERSION.txt, docker images get tagged with version when built. Documented install instructions and a brief overview for the datasets used in the public API. Makefile improvements (suggested by a user, thank you!). Increased the public API daily request limit to 1000. Updated NED on the public API. Added CORS header support.","title":"Release notes"},{"location":"changelog/#release-notes","text":"This is a list of changes to Open Topo Data between each release.","title":"Release Notes"},{"location":"changelog/#version-130-4-sep-2020","text":"Added /health endpoint.","title":"Version 1.3.0 (4 Sep 2020)"},{"location":"changelog/#version-124-8-aug-2020","text":"Support for more raster filename formats, as raised in issue #8 .","title":"Version 1.2.4 (8 Aug 2020)"},{"location":"changelog/#version-123-31-july-2020","text":"Minor documentation fixes and dependency updates.","title":"Version 1.2.3 (31 July 2020)"},{"location":"changelog/#version-122-2-july-2020","text":"Documentation fixes. I'm now using pip-tools to manage python dependencies, and I'm really liking it. Exact dependency versions are now pinned, but it's easy to update them to the latest version. Updated dependencies.","title":"Version 1.2.2 (2 July 2020)"},{"location":"changelog/#version-121-22-may-2020","text":"Improved documentation, plus some bug fixes: Fix floating-point precision issue that was breaking requests on dataset boundaries. Ignore common non-raster files.","title":"Version 1.2.1 (22 May 2020)"},{"location":"changelog/#version-120-10-may-2020","text":"Added a bunch of new datasets to the public API: GEBCO bathymetry. EMOD bathymetry. NZ 8m DEM. Mapzen 30m DEM.","title":"Version 1.2.0 (10 May 2020)"},{"location":"changelog/#version-110-25-april-2020","text":"Added this changelog! Pushing to master now means a release with a changelog entry. Added VERSION.txt, docker images get tagged with version when built. Documented install instructions and a brief overview for the datasets used in the public API. Makefile improvements (suggested by a user, thank you!). Increased the public API daily request limit to 1000. Updated NED on the public API. Added CORS header support.","title":"Version 1.1.0 (25 April 2020)"},{"location":"server/","text":"Open Topo Data Server Documentation Getting started The easiest way to run Open Topo Data is with Docker. Install docker then run the following commands: git clone https://github.com/ajnisbet/opentopodata.git cd opentopodata make build make run This will start a server on localhost:5000 with a small demo dataset called test-dataset . Check out the API docs for info about the format of requests and responses. Dataset support Open Topo Data supports all georeferenced raster formats supported by GDAL (e.g, .tiff , .hgt , .jp2 ). Datasets can take one of two formats: A single raster file. A collection of square raster tiles which follow the SRTM naming convention: the file is named for the lower left corner. So a file named N30W120.tiff would span from 30 to 31 degrees latitude, and -120 to -119 degrees longitude. By default tiles are 1\u00b0 by 1\u00b0 and the coordinates are in WGS84, but this can be configured. If your dataset consists of multiple files that aren't on a nice grid, you can create a .vrt file pointing to the files that Open Topo Data will treat as a single-file dataset. For an example of this process, see the documentation for configuring EMODnet . Configuration Open Topo Data is configured by a config.yaml file. If that file is missing it will look for example-config.yaml instead. A config might look like: max_locations_per_request : 100 access_control_allow_origin : '*' datasets : - name : etopo1 path : data/etopo1/ - name : srtm90m path : data/srtm-90m-v3/ filename_epsg : 4326 filename_tile_size : 1 corresponding to a directory structure: opentopodata | \u2514\u2500\u2500\u2500data | \u251c\u2500\u2500\u2500etopo1 | | | \u2514\u2500\u2500\u2500etopo1-dem.geotiff | \u2514\u2500\u2500\u2500srtm-90m-v3 | \u251c\u2500\u2500\u2500N00E000.hgt \u251c\u2500\u2500\u2500N00E001.hgt \u251c\u2500\u2500\u2500N00E002.hgt \u251c\u2500\u2500\u2500etc... which would expose localhost:5000/v1/etopo1 and localhost:5000/v1/srtm90m . Config spec max_locations_per_request : Requests with more than this many locations will return a 400 error. Default: 100 . access_control_allow_origin : Value for the Access-Control-Allow-Origin CORS header. Set to * or a domain to allow in-browser requests from a different origin. Set to null to send no Access-Control-Allow-Origin header. Default: null . datasets[].name : Dataset name, used in url. Required. datasets[].path : Path to folder containing the dataset. If the dataset is a single file it must be placed inside a folder. This path is relative to the repository directory inside docker. I suggest placing datasets inside the provided data folder, which is mounted in docker by make run . Files can be nested arbitrarily inside the dataset path. Required. datasets[].filename_epsg : For tiled datasets, the projection of the filename coordinates. The default value is 4326 , which is latitude/longitude with the WGS84 datum. datasets[].filename_tile_size : For tiled datasets, how large each square tile is, in the units of filename_epsg . For example, a lat,lon location of 38.2,121.2 would lie in the tile N38W121 for a tile size of 1, but lie in N35W120 for a tile size of 5. Default: 1 . Adding datasets An important goal of Open Topo Data is make is easy to add new datasets. The included dataset is very low resolution (about 100km) and is intended only for testing. Adding a new dataset takes two steps: placing the dataset in the data directory adding the path to the dataset in config.yaml . Instructions are provided for adding the various datasets used in the public API: ASTER ETOPO1 EU-DEM Mapzen NED 10m NZ DEM SRTM (30m or 90m) EMOD Bathymetry GEBCO Bathymetry Windows support Unfortunately I don't have access to a Windows machine, to can't promise support on Windows. Some users have had issues getting the docker image to run: if this happens to you, it should be possible to run Open Topo Data outside of docker, provided all the dependencies in requirements.txt and Dockerfile are installed.","title":"Server docs"},{"location":"server/#open-topo-data-server-documentation","text":"","title":"Open Topo Data Server Documentation"},{"location":"server/#getting-started","text":"The easiest way to run Open Topo Data is with Docker. Install docker then run the following commands: git clone https://github.com/ajnisbet/opentopodata.git cd opentopodata make build make run This will start a server on localhost:5000 with a small demo dataset called test-dataset . Check out the API docs for info about the format of requests and responses.","title":"Getting started"},{"location":"server/#dataset-support","text":"Open Topo Data supports all georeferenced raster formats supported by GDAL (e.g, .tiff , .hgt , .jp2 ). Datasets can take one of two formats: A single raster file. A collection of square raster tiles which follow the SRTM naming convention: the file is named for the lower left corner. So a file named N30W120.tiff would span from 30 to 31 degrees latitude, and -120 to -119 degrees longitude. By default tiles are 1\u00b0 by 1\u00b0 and the coordinates are in WGS84, but this can be configured. If your dataset consists of multiple files that aren't on a nice grid, you can create a .vrt file pointing to the files that Open Topo Data will treat as a single-file dataset. For an example of this process, see the documentation for configuring EMODnet .","title":"Dataset support"},{"location":"server/#configuration","text":"Open Topo Data is configured by a config.yaml file. If that file is missing it will look for example-config.yaml instead. A config might look like: max_locations_per_request : 100 access_control_allow_origin : '*' datasets : - name : etopo1 path : data/etopo1/ - name : srtm90m path : data/srtm-90m-v3/ filename_epsg : 4326 filename_tile_size : 1 corresponding to a directory structure: opentopodata | \u2514\u2500\u2500\u2500data | \u251c\u2500\u2500\u2500etopo1 | | | \u2514\u2500\u2500\u2500etopo1-dem.geotiff | \u2514\u2500\u2500\u2500srtm-90m-v3 | \u251c\u2500\u2500\u2500N00E000.hgt \u251c\u2500\u2500\u2500N00E001.hgt \u251c\u2500\u2500\u2500N00E002.hgt \u251c\u2500\u2500\u2500etc... which would expose localhost:5000/v1/etopo1 and localhost:5000/v1/srtm90m .","title":"Configuration"},{"location":"server/#config-spec","text":"max_locations_per_request : Requests with more than this many locations will return a 400 error. Default: 100 . access_control_allow_origin : Value for the Access-Control-Allow-Origin CORS header. Set to * or a domain to allow in-browser requests from a different origin. Set to null to send no Access-Control-Allow-Origin header. Default: null . datasets[].name : Dataset name, used in url. Required. datasets[].path : Path to folder containing the dataset. If the dataset is a single file it must be placed inside a folder. This path is relative to the repository directory inside docker. I suggest placing datasets inside the provided data folder, which is mounted in docker by make run . Files can be nested arbitrarily inside the dataset path. Required. datasets[].filename_epsg : For tiled datasets, the projection of the filename coordinates. The default value is 4326 , which is latitude/longitude with the WGS84 datum. datasets[].filename_tile_size : For tiled datasets, how large each square tile is, in the units of filename_epsg . For example, a lat,lon location of 38.2,121.2 would lie in the tile N38W121 for a tile size of 1, but lie in N35W120 for a tile size of 5. Default: 1 .","title":"Config spec"},{"location":"server/#adding-datasets","text":"An important goal of Open Topo Data is make is easy to add new datasets. The included dataset is very low resolution (about 100km) and is intended only for testing. Adding a new dataset takes two steps: placing the dataset in the data directory adding the path to the dataset in config.yaml . Instructions are provided for adding the various datasets used in the public API: ASTER ETOPO1 EU-DEM Mapzen NED 10m NZ DEM SRTM (30m or 90m) EMOD Bathymetry GEBCO Bathymetry","title":"Adding datasets"},{"location":"server/#windows-support","text":"Unfortunately I don't have access to a Windows machine, to can't promise support on Windows. Some users have had issues getting the docker image to run: if this happens to you, it should be possible to run Open Topo Data outside of docker, provided all the dependencies in requirements.txt and Dockerfile are installed.","title":"Windows support"},{"location":"datasets/aster/","text":"ASTER Overview The Advanced Spaceborne Thermal Emission and Reflection Radiometer ( ASTER ) global DEM dataset is a joint effort between the Ministry of Economy, Trade, and Industry (METI) of Japan and the National Aeronautics and Space Administration (NASA) of the US. ASTER GDEM is a 1 arc-second resolution, corresponding to a resolution of about 30m at the equator. Coverage is provided from from -83 to 83 degrees latitude. Render of ASTER elevation. Source. Adding 30m ASTER to Open Topo Data Make a new folder for the dataset: mkdir ./data/aster30m Download the files from USGS into ./data/aster30m . Extract the zip archives keeping the _dem.tif files and removing the _num.tif files. To make downloading a bit easier, here's a list of the 22,912 URLs: aster30m_urls.txt . Create a config.yaml file: datasets : - name : aster30m path : data/aster30m/ Rebuild to enable the new dataset at localhost:5000/v1/aster30m . make build && make run Public API The Open Topo Data public API lets you query ASTER GDEM 30m for free: curl https://api.opentopodata.org/v1/srtm30m?locations=57.688709,11.976404 { \"results\" : [ { \"elevation\" : 55.0 , \"location\" : { \"lat\" : 57.688709 , \"lng\" : 11.976404 } } ], \"status\" : \"OK\" } The Public API used version 3 of the DEM (GDEM 003).","title":"ASTER"},{"location":"datasets/aster/#aster","text":"","title":"ASTER"},{"location":"datasets/aster/#overview","text":"The Advanced Spaceborne Thermal Emission and Reflection Radiometer ( ASTER ) global DEM dataset is a joint effort between the Ministry of Economy, Trade, and Industry (METI) of Japan and the National Aeronautics and Space Administration (NASA) of the US. ASTER GDEM is a 1 arc-second resolution, corresponding to a resolution of about 30m at the equator. Coverage is provided from from -83 to 83 degrees latitude. Render of ASTER elevation. Source.","title":"Overview"},{"location":"datasets/aster/#adding-30m-aster-to-open-topo-data","text":"Make a new folder for the dataset: mkdir ./data/aster30m Download the files from USGS into ./data/aster30m . Extract the zip archives keeping the _dem.tif files and removing the _num.tif files. To make downloading a bit easier, here's a list of the 22,912 URLs: aster30m_urls.txt . Create a config.yaml file: datasets : - name : aster30m path : data/aster30m/ Rebuild to enable the new dataset at localhost:5000/v1/aster30m . make build && make run","title":"Adding 30m ASTER to Open Topo Data"},{"location":"datasets/aster/#public-api","text":"The Open Topo Data public API lets you query ASTER GDEM 30m for free: curl https://api.opentopodata.org/v1/srtm30m?locations=57.688709,11.976404 { \"results\" : [ { \"elevation\" : 55.0 , \"location\" : { \"lat\" : 57.688709 , \"lng\" : 11.976404 } } ], \"status\" : \"OK\" } The Public API used version 3 of the DEM (GDEM 003).","title":"Public API"},{"location":"datasets/emod2018/","text":"EMODnet 2018 Bathymetry EMODnet maintains a number of bathymetry (sea floor depth) datasets. There are currently two datasets with full coverage of Europe: a 1/8 arc minute (~200m) version released in 2016, and a 1/16 arc minute (~100m) version released in 2018. The datasets are a composite of bathymetric surveys, Landsat 8 imagery, and GEBCO data. The vertical datum used is Lowest Astronomical Tide . Coverage The 2018 dataset covers a large area around Europe: 15\u00b0 to 90\u00b0 latitude, and -36\u00b0 to 43\u00b0 longitude. The elevation over land areas is given as NODATA values. Render of EMODnet 2018 sea floor depth. Adding EMODnet 2018 Bathymetry to Open Topo Data Make a new folder for the dataset: mkdir ./data/emod2018 Download the files from EMODnet into ./data/emod2018 . You want the 2018 dataset, in ESRI ASCII format. Extract the zip folders, you should have 59 .asc named like A1_2018.asc . Unlike other datasets, the EMOD tiles aren't aligned on a nice whole-number grid, so Open Topo Data can't tell from the filenames which tile covers which area. To handle this we can build a https://gdal.org/drivers/raster/vrt.html - a single raster file that links to the 59 tiles and which Open Topo Data can treat as a single-file dataset. Unfortunately you'll need to install GDAL for this. Create a new folder for the VRT: mkdir ./data/emod2018-vrt Build the vrt using relative paths so the file will work inside the docker image: cd ./data/emod2018-vrt gdalbuildvrt -co VRT_SHARED_SOURCE = 0 emod2018.vrt ../emod2018/*.asc cd ../ Create a config.yaml file, pointing to the VRT folder: datasets : - name : emod2018 path : data/emod2018-vrt/ Rebuild to enable the new dataset at localhost:5000/v1/emod2018 . make build && make run Extra performance .asc files take up a lot of disk space and are slow for random reads. Consider converting to a compressed geotiff: bash gdal_translate -co COMPRESS=DEFLATE -co PREDICTOR=2 {asc_filename} {tif_filename} Public API The Open Topo Data public API lets you query NED 10m for free: curl https://api.opentopodata.org/v1/emod2018?locations=55.884323,2.528276 { \"results\" : [ { \"elevation\" : -81.94999694824219 , \"location\" : { \"lat\" : 55.884323 , \"lng\" : 2.528276 } } ], \"status\" : \"OK\" } The public API uses the 2018 version of the dataset.","title":"EMOD Bathymetry"},{"location":"datasets/emod2018/#emodnet-2018-bathymetry","text":"EMODnet maintains a number of bathymetry (sea floor depth) datasets. There are currently two datasets with full coverage of Europe: a 1/8 arc minute (~200m) version released in 2016, and a 1/16 arc minute (~100m) version released in 2018. The datasets are a composite of bathymetric surveys, Landsat 8 imagery, and GEBCO data. The vertical datum used is Lowest Astronomical Tide .","title":"EMODnet 2018 Bathymetry"},{"location":"datasets/emod2018/#coverage","text":"The 2018 dataset covers a large area around Europe: 15\u00b0 to 90\u00b0 latitude, and -36\u00b0 to 43\u00b0 longitude. The elevation over land areas is given as NODATA values. Render of EMODnet 2018 sea floor depth.","title":"Coverage"},{"location":"datasets/emod2018/#adding-emodnet-2018-bathymetry-to-open-topo-data","text":"Make a new folder for the dataset: mkdir ./data/emod2018 Download the files from EMODnet into ./data/emod2018 . You want the 2018 dataset, in ESRI ASCII format. Extract the zip folders, you should have 59 .asc named like A1_2018.asc . Unlike other datasets, the EMOD tiles aren't aligned on a nice whole-number grid, so Open Topo Data can't tell from the filenames which tile covers which area. To handle this we can build a https://gdal.org/drivers/raster/vrt.html - a single raster file that links to the 59 tiles and which Open Topo Data can treat as a single-file dataset. Unfortunately you'll need to install GDAL for this. Create a new folder for the VRT: mkdir ./data/emod2018-vrt Build the vrt using relative paths so the file will work inside the docker image: cd ./data/emod2018-vrt gdalbuildvrt -co VRT_SHARED_SOURCE = 0 emod2018.vrt ../emod2018/*.asc cd ../ Create a config.yaml file, pointing to the VRT folder: datasets : - name : emod2018 path : data/emod2018-vrt/ Rebuild to enable the new dataset at localhost:5000/v1/emod2018 . make build && make run Extra performance .asc files take up a lot of disk space and are slow for random reads. Consider converting to a compressed geotiff: bash gdal_translate -co COMPRESS=DEFLATE -co PREDICTOR=2 {asc_filename} {tif_filename}","title":"Adding EMODnet 2018 Bathymetry to Open Topo Data"},{"location":"datasets/emod2018/#public-api","text":"The Open Topo Data public API lets you query NED 10m for free: curl https://api.opentopodata.org/v1/emod2018?locations=55.884323,2.528276 { \"results\" : [ { \"elevation\" : -81.94999694824219 , \"location\" : { \"lat\" : 55.884323 , \"lng\" : 2.528276 } } ], \"status\" : \"OK\" } The public API uses the 2018 version of the dataset.","title":"Public API"},{"location":"datasets/etopo1/","text":"ETOPO1 Overview ETOPO1 is a global elevation dataset developed by NOAA. Unlike many DEM datasets, ETOPO1 contains bathymetry (water depth). There are two variants of the dataset, which vary in how elevation is calculated for the Antartic and Greenland ice sheets: an ice-surface variant, and a bedrock-level variant. The dataset has a 1 arc-minute resolution, which corresponds to a resolution of about 1.8km at the equator. ETOPO1 was made by aggregating many other datasets. The bulk of the land elevation comes from SRTM30, while most bathymetry is sourced from GEBCO . The comprising datasets were normalised to the same vertical datum (sea level) and horizontal datum (WGS84). Accuracy The accuracy of ETOPO1 varies spatially depending on the underlying source data. NOAA estimates the vertical accuracy is no better than 10m. The quality of ETOPO1 is high: there are no missing values or holes (holes in the SRTM30 source were fixed by hand). Transitions between source datasets are smooth. Pseudocolour render of ETOPO1 elevation. Adding ETOPO1 to Open Topo Data Download the grid-registered .tif file from noaa.gov to the data directory and unzip. mkdir ./data/etopo1 wget -P ./data/etopo1 https://www.ngdc.noaa.gov/mgg/global/relief/ETOPO1/data/ice_surface/grid_registered/georeferenced_tiff/ETOPO1_Ice_g_geotiff.zip unzip ./data/etopo1/ETOPO1_Ice_g_geotiff.zip rm ./data/etopo1/ETOPO1_Ice_g_geotiff.zip The provided .tif file doesn't include projection information, which is needed for Open Topo Data. It can be added with GDAL: gdal_translate -a_srs EPSG:4326 ./data/etopo1/ETOPO1_Ice_g_geotiff.tif ./data/etopo1/ETOPO1.tif rm ./data/etopo1/ETOPO1_Ice_g_geotiff.tif Create a file config.yaml with the following contents datasets : - name : etopo1 path : data/etopo1/ Rebuild to enable the new dataset at localhost:5000/v1/etopo1?locations=27.98,86.92 make build && make run Public API The Open Topo Data public API lets you query ETOPO1 for free: curl https://api.opentopodata.org/v1/etopo1?locations=39.747114,-104.996334 { \"results\" : [ { \"elevation\" : 1596.0 , \"location\" : { \"lat\" : 39.747114 , \"lng\" : -104.996334 } } ], \"status\" : \"OK\" } Open Topo Data hosts the ice-elevation version of the dataset (the same as seen in the image above).","title":"ETOPO1"},{"location":"datasets/etopo1/#etopo1","text":"","title":"ETOPO1"},{"location":"datasets/etopo1/#overview","text":"ETOPO1 is a global elevation dataset developed by NOAA. Unlike many DEM datasets, ETOPO1 contains bathymetry (water depth). There are two variants of the dataset, which vary in how elevation is calculated for the Antartic and Greenland ice sheets: an ice-surface variant, and a bedrock-level variant. The dataset has a 1 arc-minute resolution, which corresponds to a resolution of about 1.8km at the equator. ETOPO1 was made by aggregating many other datasets. The bulk of the land elevation comes from SRTM30, while most bathymetry is sourced from GEBCO . The comprising datasets were normalised to the same vertical datum (sea level) and horizontal datum (WGS84).","title":"Overview"},{"location":"datasets/etopo1/#accuracy","text":"The accuracy of ETOPO1 varies spatially depending on the underlying source data. NOAA estimates the vertical accuracy is no better than 10m. The quality of ETOPO1 is high: there are no missing values or holes (holes in the SRTM30 source were fixed by hand). Transitions between source datasets are smooth. Pseudocolour render of ETOPO1 elevation.","title":"Accuracy"},{"location":"datasets/etopo1/#adding-etopo1-to-open-topo-data","text":"Download the grid-registered .tif file from noaa.gov to the data directory and unzip. mkdir ./data/etopo1 wget -P ./data/etopo1 https://www.ngdc.noaa.gov/mgg/global/relief/ETOPO1/data/ice_surface/grid_registered/georeferenced_tiff/ETOPO1_Ice_g_geotiff.zip unzip ./data/etopo1/ETOPO1_Ice_g_geotiff.zip rm ./data/etopo1/ETOPO1_Ice_g_geotiff.zip The provided .tif file doesn't include projection information, which is needed for Open Topo Data. It can be added with GDAL: gdal_translate -a_srs EPSG:4326 ./data/etopo1/ETOPO1_Ice_g_geotiff.tif ./data/etopo1/ETOPO1.tif rm ./data/etopo1/ETOPO1_Ice_g_geotiff.tif Create a file config.yaml with the following contents datasets : - name : etopo1 path : data/etopo1/ Rebuild to enable the new dataset at localhost:5000/v1/etopo1?locations=27.98,86.92 make build && make run","title":"Adding ETOPO1 to Open Topo Data"},{"location":"datasets/etopo1/#public-api","text":"The Open Topo Data public API lets you query ETOPO1 for free: curl https://api.opentopodata.org/v1/etopo1?locations=39.747114,-104.996334 { \"results\" : [ { \"elevation\" : 1596.0 , \"location\" : { \"lat\" : 39.747114 , \"lng\" : -104.996334 } } ], \"status\" : \"OK\" } Open Topo Data hosts the ice-elevation version of the dataset (the same as seen in the image above).","title":"Public API"},{"location":"datasets/eudem/","text":"EU-DEM EU-DEM is an elevation dataset covering Europe at a 25 metre resolution. The dataset was created by merging elevation data from the SRTM and ASTER global datasets, as well as from Soviet topo maps at high latitudes. The datum used is EVRS2000 . Coverage The dataset covers European Environment Agency member states, plus some countries to the east. Coverage extends to small parts of Northern Africa. Unlike SRTM, EU-DEM includes the Scandinavian regions north of 60\u00b0. Render of ETOPO1 elevation. Accuracy The stated vertical accuracy is \u00b1 7m RMSE. Differences to SRTM and ASTER typically fall within this 7m range even with the datasets using slightly different vertical datums. Elevations for Lake Geneva, Switzerland are 370m , 374m , and 372m for SRTM, ASTER, and EU-DEM respectively. Coastline EU-DEM uses NODATA values for elevations over seas and oceans, where both ASTER and SRTM assign these areas an elevation of 0m. This means that Open Topo Data isn't able to interpolate elevations for locations very close to the coast and will return a value of NaN in places where SRTM and ASTER might return a 0m or 1m elevation. The advantage of the NODATA oceans is that you cane use EU-DEM without clipping to a coastline shapefile. Adding EU-DEM to Open Topo Data Make a new folder for the dataset: mkdir ./data/eudem Download the dataset from Copernicus . There are 27 files. Unzip them and move all the .TIF files into the data folder (you don't need the .aux.xml , .ovr , or .TFw files). Your data folder should now contain only 27 TIF files: ls ./data/eudem # eu_dem_v11_E00N20.TIF # eu_dem_v11_E10N00.TIF # eu_dem_v11_E10N10.TIF # ... Next, Open Topo Data needs the filenames to match the SRTM format: the filename should be the coordinates of the lower-left corner, in NS-WE order. For EU-DEM this means two changes to the filenames: swapping the order of the northing and easting, and adding 5 trailing zeroes to each coordinate that Copernicus removed for simplicity. So eu_dem_v11_E00N20.TIF becomes N2000000E0000000.tif . Here's a Python script to do the transformation, but it might be just as easy to do by hand: from glob import glob import os import re old_pattern = './data/eudem/eu_dem_v11_E*N*.TIF' old_paths = list ( glob ( old_pattern )) print ( 'Found {} files' . format ( len ( old_paths ))) for old_path in old_paths : folder = os . path . dirname ( old_path ) old_filename = os . path . basename ( old_path ) # Extract north and east coords, pad with zeroes. res = re . search ( r '(E\\d\\d)(N\\d\\d)' , old_filename ) easting , northing = res . groups () northing = northing + '00000' easting = easting + '00000' # Rename in place. new_filename = ' {}{} .tif' . format ( northing , easting ) new_path = os . path . join ( folder , new_filename ) os . rename ( old_path , new_path ) You should have the following 27 files: N0000000E1000000.tif N1000000E1000000.tif N1000000E2000000.tif N1000000E3000000.tif N1000000E4000000.tif N1000000E5000000.tif N1000000E6000000.tif N2000000E0000000.tif N2000000E1000000.tif N2000000E2000000.tif N2000000E3000000.tif N2000000E4000000.tif N2000000E5000000.tif N2000000E6000000.tif N2000000E7000000.tif N3000000E2000000.tif N3000000E3000000.tif N3000000E4000000.tif N3000000E5000000.tif N4000000E2000000.tif N4000000E3000000.tif N4000000E4000000.tif N4000000E5000000.tif N5000000E2000000.tif N5000000E3000000.tif N5000000E4000000.tif N5000000E5000000.tif Create a config.yaml file: datasets : - name : eudem25m path : data/eudem/ filename_epsg : 3035 filename_tile_size : 1000000 Rebuild to enable the new dataset at localhost:5000/v1/eudem25m?locations=51.575,-3.220 . make build && make run Public API The Open Topo Data public API lets you query EU-DEM for free: curl https://api.opentopodata.org/v1/eudem25m?locations=57.688709,11.976404 { \"results\" : [ { \"elevation\" : 54.576168060302734 , \"location\" : { \"lat\" : 57.688709 , \"lng\" : 11.976404 } } ], \"status\" : \"OK\" } Open Topo Data hosts version 1.1 of the dataset.","title":"EU-DEM"},{"location":"datasets/eudem/#eu-dem","text":"EU-DEM is an elevation dataset covering Europe at a 25 metre resolution. The dataset was created by merging elevation data from the SRTM and ASTER global datasets, as well as from Soviet topo maps at high latitudes. The datum used is EVRS2000 .","title":"EU-DEM"},{"location":"datasets/eudem/#coverage","text":"The dataset covers European Environment Agency member states, plus some countries to the east. Coverage extends to small parts of Northern Africa. Unlike SRTM, EU-DEM includes the Scandinavian regions north of 60\u00b0. Render of ETOPO1 elevation.","title":"Coverage"},{"location":"datasets/eudem/#accuracy","text":"The stated vertical accuracy is \u00b1 7m RMSE. Differences to SRTM and ASTER typically fall within this 7m range even with the datasets using slightly different vertical datums. Elevations for Lake Geneva, Switzerland are 370m , 374m , and 372m for SRTM, ASTER, and EU-DEM respectively.","title":"Accuracy"},{"location":"datasets/eudem/#coastline","text":"EU-DEM uses NODATA values for elevations over seas and oceans, where both ASTER and SRTM assign these areas an elevation of 0m. This means that Open Topo Data isn't able to interpolate elevations for locations very close to the coast and will return a value of NaN in places where SRTM and ASTER might return a 0m or 1m elevation. The advantage of the NODATA oceans is that you cane use EU-DEM without clipping to a coastline shapefile.","title":"Coastline"},{"location":"datasets/eudem/#adding-eu-dem-to-open-topo-data","text":"Make a new folder for the dataset: mkdir ./data/eudem Download the dataset from Copernicus . There are 27 files. Unzip them and move all the .TIF files into the data folder (you don't need the .aux.xml , .ovr , or .TFw files). Your data folder should now contain only 27 TIF files: ls ./data/eudem # eu_dem_v11_E00N20.TIF # eu_dem_v11_E10N00.TIF # eu_dem_v11_E10N10.TIF # ... Next, Open Topo Data needs the filenames to match the SRTM format: the filename should be the coordinates of the lower-left corner, in NS-WE order. For EU-DEM this means two changes to the filenames: swapping the order of the northing and easting, and adding 5 trailing zeroes to each coordinate that Copernicus removed for simplicity. So eu_dem_v11_E00N20.TIF becomes N2000000E0000000.tif . Here's a Python script to do the transformation, but it might be just as easy to do by hand: from glob import glob import os import re old_pattern = './data/eudem/eu_dem_v11_E*N*.TIF' old_paths = list ( glob ( old_pattern )) print ( 'Found {} files' . format ( len ( old_paths ))) for old_path in old_paths : folder = os . path . dirname ( old_path ) old_filename = os . path . basename ( old_path ) # Extract north and east coords, pad with zeroes. res = re . search ( r '(E\\d\\d)(N\\d\\d)' , old_filename ) easting , northing = res . groups () northing = northing + '00000' easting = easting + '00000' # Rename in place. new_filename = ' {}{} .tif' . format ( northing , easting ) new_path = os . path . join ( folder , new_filename ) os . rename ( old_path , new_path ) You should have the following 27 files: N0000000E1000000.tif N1000000E1000000.tif N1000000E2000000.tif N1000000E3000000.tif N1000000E4000000.tif N1000000E5000000.tif N1000000E6000000.tif N2000000E0000000.tif N2000000E1000000.tif N2000000E2000000.tif N2000000E3000000.tif N2000000E4000000.tif N2000000E5000000.tif N2000000E6000000.tif N2000000E7000000.tif N3000000E2000000.tif N3000000E3000000.tif N3000000E4000000.tif N3000000E5000000.tif N4000000E2000000.tif N4000000E3000000.tif N4000000E4000000.tif N4000000E5000000.tif N5000000E2000000.tif N5000000E3000000.tif N5000000E4000000.tif N5000000E5000000.tif Create a config.yaml file: datasets : - name : eudem25m path : data/eudem/ filename_epsg : 3035 filename_tile_size : 1000000 Rebuild to enable the new dataset at localhost:5000/v1/eudem25m?locations=51.575,-3.220 . make build && make run","title":"Adding EU-DEM to Open Topo Data"},{"location":"datasets/eudem/#public-api","text":"The Open Topo Data public API lets you query EU-DEM for free: curl https://api.opentopodata.org/v1/eudem25m?locations=57.688709,11.976404 { \"results\" : [ { \"elevation\" : 54.576168060302734 , \"location\" : { \"lat\" : 57.688709 , \"lng\" : 11.976404 } } ], \"status\" : \"OK\" } Open Topo Data hosts version 1.1 of the dataset.","title":"Public API"},{"location":"datasets/gebco2020/","text":"GEBCO 2020 Bathymetry GEBCO maintains a high-quality, global bathymetry (sea floor depth) dataset. GEBCO releases a new dataset most years, the 2020 dataset (released in May 2020) covers the entire globe at a 15 arc-second resolution, corresponding to 450m resolution at the equator. Coverage Elevation is given for land areas, largely using a 15-degree version of SRTM . Seafloor data comes from a variety of bathymetric sources, see GEBCO for more details. Render of GEBCO 2020 elevation. Adding GEBCO 2020 to Open Topo Data Instructions are given for the 2020 version of the dataset: future versions might work a bit differently. Make a new folder for the dataset: mkdir ./data/gebco2020 Download the dataset from GEBCO . You'll want the GEBCO_2020 Grid version, in Data GeoTiff format. Extract raster tiles from the archive and delete everything else so there are just 8 .tif files in the ./data/gebco2020 folder. The files are given as 90 degree tiles, we need to rename them to SRTM's NxxSxx format to work with Open Topo Data: mv gebco_2020_n0.0_s-90.0_w0.0_e90.0.tif S90E000.tif mv gebco_2020_n0.0_s-90.0_w-180.0_e-90.0.tif S90W180.tif mv gebco_2020_n0.0_s-90.0_w-90.0_e0.0.tif S90W090.tif mv gebco_2020_n0.0_s-90.0_w90.0_e180.0.tif S90E090.tif mv gebco_2020_n90.0_s0.0_w0.0_e90.0.tif N00E000.tif mv gebco_2020_n90.0_s0.0_w-180.0_e-90.0.tif N00W180.tif mv gebco_2020_n90.0_s0.0_w-90.0_e0.0.tif N00W090.tif mv gebco_2020_n90.0_s0.0_w90.0_e180.0.tif N00E090.tif Create a config.yaml file: datasets : - name : gebco2020 path : data/gebco2020/ filename_tile_size : 90 Rebuild to enable the new dataset at localhost:5000/v1/gebco2020 . make build && make run Buffering tiles The tiles provided by GEBCO don't overlap and cover slightly less than a 90\u00b0 x 90\u00b0 square. This means you'll get a null result for coordinates along the tile edges (like 0,0 ). For the public API I used the following code to add a 5px buffer to each tile. from glob import glob import os import rasterio old_folder = 'gebco_2020_geotiff' new_folder = 'gebco_2020_buffer' buffer_ = 5 old_pattern = os . path . join ( old_folder , '*.tif' ) old_paths = list ( glob ( old_pattern )) cmd = 'gdalbuildvrt {} /all.vrt' . format ( old_folder ) + ' ' . join ( old_paths ) os . system ( cmd ) for path in old_paths : new_path = path . replace ( old_folder , new_folder ) with rasterio . open ( path ) as f : new_bounds = ( f . bounds . left - buffer_ * f . res [ 0 ], f . bounds . bottom - buffer_ * f . res [ 1 ], f . bounds . right + buffer_ * f . res [ 0 ], f . bounds . top + buffer_ * f . res [ 1 ], ) new_shape = ( f . shape [ 0 ] + buffer_ * 2 , f . shape [ 1 ] + buffer_ * 2 , ) te = ' ' . join ( str ( x ) for x in new_bounds ) ts = ' ' . join ( str ( x ) for x in new_shape ) cmd = f 'gdalwarp -te {te} -ts {ts} -r near -co NUM_THREADS=ALL_CPUS -co COMPRESS=DEFLATE -co PREDICTOR=2 -co BIGTIFF=yes {old_folder} /all.vrt {new_path} ' os . system ( cmd ) Public API The Open Topo Data public API lets you query GEBCO 2020 for free: curl https://api.opentopodata.org/v1/gebco2020?locations=37.6535,-119.4105 { \"results\" : [ { \"elevation\" : 3405.0 , \"location\" : { \"lat\" : 37.6535 , \"lng\" : -119.4105 } } ], \"status\" : \"OK\" } The public API uses the 2020 version of the dataset.","title":"GEBCO Bathymetry"},{"location":"datasets/gebco2020/#gebco-2020-bathymetry","text":"GEBCO maintains a high-quality, global bathymetry (sea floor depth) dataset. GEBCO releases a new dataset most years, the 2020 dataset (released in May 2020) covers the entire globe at a 15 arc-second resolution, corresponding to 450m resolution at the equator.","title":"GEBCO 2020 Bathymetry"},{"location":"datasets/gebco2020/#coverage","text":"Elevation is given for land areas, largely using a 15-degree version of SRTM . Seafloor data comes from a variety of bathymetric sources, see GEBCO for more details. Render of GEBCO 2020 elevation.","title":"Coverage"},{"location":"datasets/gebco2020/#adding-gebco-2020-to-open-topo-data","text":"Instructions are given for the 2020 version of the dataset: future versions might work a bit differently. Make a new folder for the dataset: mkdir ./data/gebco2020 Download the dataset from GEBCO . You'll want the GEBCO_2020 Grid version, in Data GeoTiff format. Extract raster tiles from the archive and delete everything else so there are just 8 .tif files in the ./data/gebco2020 folder. The files are given as 90 degree tiles, we need to rename them to SRTM's NxxSxx format to work with Open Topo Data: mv gebco_2020_n0.0_s-90.0_w0.0_e90.0.tif S90E000.tif mv gebco_2020_n0.0_s-90.0_w-180.0_e-90.0.tif S90W180.tif mv gebco_2020_n0.0_s-90.0_w-90.0_e0.0.tif S90W090.tif mv gebco_2020_n0.0_s-90.0_w90.0_e180.0.tif S90E090.tif mv gebco_2020_n90.0_s0.0_w0.0_e90.0.tif N00E000.tif mv gebco_2020_n90.0_s0.0_w-180.0_e-90.0.tif N00W180.tif mv gebco_2020_n90.0_s0.0_w-90.0_e0.0.tif N00W090.tif mv gebco_2020_n90.0_s0.0_w90.0_e180.0.tif N00E090.tif Create a config.yaml file: datasets : - name : gebco2020 path : data/gebco2020/ filename_tile_size : 90 Rebuild to enable the new dataset at localhost:5000/v1/gebco2020 . make build && make run","title":"Adding GEBCO 2020 to Open Topo Data"},{"location":"datasets/gebco2020/#buffering-tiles","text":"The tiles provided by GEBCO don't overlap and cover slightly less than a 90\u00b0 x 90\u00b0 square. This means you'll get a null result for coordinates along the tile edges (like 0,0 ). For the public API I used the following code to add a 5px buffer to each tile. from glob import glob import os import rasterio old_folder = 'gebco_2020_geotiff' new_folder = 'gebco_2020_buffer' buffer_ = 5 old_pattern = os . path . join ( old_folder , '*.tif' ) old_paths = list ( glob ( old_pattern )) cmd = 'gdalbuildvrt {} /all.vrt' . format ( old_folder ) + ' ' . join ( old_paths ) os . system ( cmd ) for path in old_paths : new_path = path . replace ( old_folder , new_folder ) with rasterio . open ( path ) as f : new_bounds = ( f . bounds . left - buffer_ * f . res [ 0 ], f . bounds . bottom - buffer_ * f . res [ 1 ], f . bounds . right + buffer_ * f . res [ 0 ], f . bounds . top + buffer_ * f . res [ 1 ], ) new_shape = ( f . shape [ 0 ] + buffer_ * 2 , f . shape [ 1 ] + buffer_ * 2 , ) te = ' ' . join ( str ( x ) for x in new_bounds ) ts = ' ' . join ( str ( x ) for x in new_shape ) cmd = f 'gdalwarp -te {te} -ts {ts} -r near -co NUM_THREADS=ALL_CPUS -co COMPRESS=DEFLATE -co PREDICTOR=2 -co BIGTIFF=yes {old_folder} /all.vrt {new_path} ' os . system ( cmd )","title":"Buffering tiles"},{"location":"datasets/gebco2020/#public-api","text":"The Open Topo Data public API lets you query GEBCO 2020 for free: curl https://api.opentopodata.org/v1/gebco2020?locations=37.6535,-119.4105 { \"results\" : [ { \"elevation\" : 3405.0 , \"location\" : { \"lat\" : 37.6535 , \"lng\" : -119.4105 } } ], \"status\" : \"OK\" } The public API uses the 2020 version of the dataset.","title":"Public API"},{"location":"datasets/mapzen/","text":"Mapzen Mapzen's terrain tiles are a global DEM dataset, including bathymetry. The dataset is an assimilation of multiple open datasets . Coverage and resolution Data is provided at a 1 arc-second resolution, corresponding to a resolution of about 30m at the equator. However, parts of the dataset are interpolated from lower-resolution datasets. The resolution of the source datasets is shown below: Resolution of Mapzen source datasets. Source: github.com/tilezen/joerd . Adding Mapzen to Open Topo Data Make a new folder for the dataset: mkdir ./data/mapzen Download the tiles from AWS. I found it easiest to use the aws cli : aws s3 cp --no-sign-request --recursive s3://elevation-tiles-prod/skadi ./data/mapzen Extract all the .hgt files. Create a config.yaml file: datasets : - name : mapzen path : data/mapzen/ Rebuild to enable the new dataset at localhost:5000/v1/mapzen . make build && make run Extra performance .hgt files are extremely large. You'll get a large space reduction with little read penalty by converting to a compressed geotiff: bash gdal_translate -co COMPRESS=DEFLATE -co PREDICTOR=2 {hgt_filename} {tif_filename} Public API The Open Topo Data public API lets you query the Mapzen dataset for free: curl https://api.opentopodata.org/v1/mapzen?locations=57.688709,11.976404 { \"results\" : [ { \"elevation\" : 55.0 , \"location\" : { \"lat\" : 57.688709 , \"lng\" : 11.976404 } } ], \"status\" : \"OK\" } The public API uses Version 1.1 of Mapzen, downloaded from AWS on May 2020","title":"Mapzen"},{"location":"datasets/mapzen/#mapzen","text":"Mapzen's terrain tiles are a global DEM dataset, including bathymetry. The dataset is an assimilation of multiple open datasets .","title":"Mapzen"},{"location":"datasets/mapzen/#coverage-and-resolution","text":"Data is provided at a 1 arc-second resolution, corresponding to a resolution of about 30m at the equator. However, parts of the dataset are interpolated from lower-resolution datasets. The resolution of the source datasets is shown below: Resolution of Mapzen source datasets. Source: github.com/tilezen/joerd .","title":"Coverage and resolution"},{"location":"datasets/mapzen/#adding-mapzen-to-open-topo-data","text":"Make a new folder for the dataset: mkdir ./data/mapzen Download the tiles from AWS. I found it easiest to use the aws cli : aws s3 cp --no-sign-request --recursive s3://elevation-tiles-prod/skadi ./data/mapzen Extract all the .hgt files. Create a config.yaml file: datasets : - name : mapzen path : data/mapzen/ Rebuild to enable the new dataset at localhost:5000/v1/mapzen . make build && make run Extra performance .hgt files are extremely large. You'll get a large space reduction with little read penalty by converting to a compressed geotiff: bash gdal_translate -co COMPRESS=DEFLATE -co PREDICTOR=2 {hgt_filename} {tif_filename}","title":"Adding Mapzen to Open Topo Data"},{"location":"datasets/mapzen/#public-api","text":"The Open Topo Data public API lets you query the Mapzen dataset for free: curl https://api.opentopodata.org/v1/mapzen?locations=57.688709,11.976404 { \"results\" : [ { \"elevation\" : 55.0 , \"location\" : { \"lat\" : 57.688709 , \"lng\" : 11.976404 } } ], \"status\" : \"OK\" } The public API uses Version 1.1 of Mapzen, downloaded from AWS on May 2020","title":"Public API"},{"location":"datasets/ned/","text":"NED The National Elevation Dataset (NED) is a collection of DEMs covering the USA at different resolutions. Resolution and Coverage NED comes in several different resolutions, each with a different coverage area. The most commonly used resolutions are 1 arcsecond (covering North America and Mexico) and 1/3 arcsecond (covering CONUS, HI, PR, and parts of AK). The 1/3 arcsecond dataset is used in the Open Topo Data public API. 1 arcsecond (30m). 1/3 arcsecond (10m). Two higher resolutions have partial coverage focused on more urbanised areas. 1/9 arcsecond (3m). 1m. And there are separate datasets with full coverage of Alaska at 2 arseconds (60m) and 5m. 2 arcsecond (60). 5m. Coverage screenshots are from The National Map . Adding NED 10m to Open Topo Data Make a new folder for the dataset: mkdir ./data/ned10m Download the files from USGS into ./data/ned10m . You want the USGS_13_xxxxxxx.tif files. Next, Open Topo Data needs the filenames to match the SRTM format: the filename should be the coordinates of the lower-left corner. Here's the Python code I used to do the conversion. from glob import glob import os import re old_pattern = './data/ned10m/USGS_13_*.tif' old_paths = list ( glob ( old_pattern )) print ( 'Found {} files' . format ( len ( old_paths ))) for old_path in old_paths : folder = os . path . dirname ( old_path ) old_filename = os . path . basename ( old_path ) # Extract northing. res = re . search ( r '([ns]\\d\\d)' , old_filename ) old_northing = res . groups ()[ 0 ] # Fix the NS n_or_s = old_northing [ 0 ] ns_value = int ( old_northing [ 1 : 3 ]) if old_northing [: 3 ] == 'n00' : new_northing = 's01' + old_northing [ 3 :] elif n_or_s == 'n' : new_northing = 'n' + str ( ns_value - 1 ) . zfill ( 2 ) + old_northing [ 3 :] elif n_or_s == 's' : new_northing = 's' + str ( ns_value + 1 ) . zfill ( 2 ) + old_northing [ 3 :] new_filename = old_filename . replace ( old_northing , new_northing ) assert new_northing in new_filename # Prevent new filename from overwriting old tiles. parts = new_filename . split ( '.' ) parts [ 0 ] = parts [ 0 ] + '_renamed' new_filename = '.' . join ( parts ) # Rename in place. new_path = os . path . join ( folder , new_filename ) os . rename ( old_path , new_path ) Create a config.yaml file: datasets : - name : ned10m path : data/ned10m/ filename_epsg : 4269 Rebuild to enable the new dataset at localhost:5000/v1/ned10m . make build && make run Public API The Open Topo Data public API lets you query NED 10m for free: curl https://api.opentopodata.org/v1/ned10m?locations=37.6535,-119.4105 { \"results\" : [ { \"elevation\" : 3498.298583984375 , \"location\" : { \"lat\" : 37.6535 , \"lng\" : -119.4105 } } ], \"status\" : \"OK\" } NED is still being updated by USGS. The dataset used by the public API was last updated 2020-04-23.","title":"NED"},{"location":"datasets/ned/#ned","text":"The National Elevation Dataset (NED) is a collection of DEMs covering the USA at different resolutions.","title":"NED"},{"location":"datasets/ned/#resolution-and-coverage","text":"NED comes in several different resolutions, each with a different coverage area. The most commonly used resolutions are 1 arcsecond (covering North America and Mexico) and 1/3 arcsecond (covering CONUS, HI, PR, and parts of AK). The 1/3 arcsecond dataset is used in the Open Topo Data public API. 1 arcsecond (30m). 1/3 arcsecond (10m). Two higher resolutions have partial coverage focused on more urbanised areas. 1/9 arcsecond (3m). 1m. And there are separate datasets with full coverage of Alaska at 2 arseconds (60m) and 5m. 2 arcsecond (60). 5m. Coverage screenshots are from The National Map .","title":"Resolution and Coverage"},{"location":"datasets/ned/#adding-ned-10m-to-open-topo-data","text":"Make a new folder for the dataset: mkdir ./data/ned10m Download the files from USGS into ./data/ned10m . You want the USGS_13_xxxxxxx.tif files. Next, Open Topo Data needs the filenames to match the SRTM format: the filename should be the coordinates of the lower-left corner. Here's the Python code I used to do the conversion. from glob import glob import os import re old_pattern = './data/ned10m/USGS_13_*.tif' old_paths = list ( glob ( old_pattern )) print ( 'Found {} files' . format ( len ( old_paths ))) for old_path in old_paths : folder = os . path . dirname ( old_path ) old_filename = os . path . basename ( old_path ) # Extract northing. res = re . search ( r '([ns]\\d\\d)' , old_filename ) old_northing = res . groups ()[ 0 ] # Fix the NS n_or_s = old_northing [ 0 ] ns_value = int ( old_northing [ 1 : 3 ]) if old_northing [: 3 ] == 'n00' : new_northing = 's01' + old_northing [ 3 :] elif n_or_s == 'n' : new_northing = 'n' + str ( ns_value - 1 ) . zfill ( 2 ) + old_northing [ 3 :] elif n_or_s == 's' : new_northing = 's' + str ( ns_value + 1 ) . zfill ( 2 ) + old_northing [ 3 :] new_filename = old_filename . replace ( old_northing , new_northing ) assert new_northing in new_filename # Prevent new filename from overwriting old tiles. parts = new_filename . split ( '.' ) parts [ 0 ] = parts [ 0 ] + '_renamed' new_filename = '.' . join ( parts ) # Rename in place. new_path = os . path . join ( folder , new_filename ) os . rename ( old_path , new_path ) Create a config.yaml file: datasets : - name : ned10m path : data/ned10m/ filename_epsg : 4269 Rebuild to enable the new dataset at localhost:5000/v1/ned10m . make build && make run","title":"Adding NED 10m to Open Topo Data"},{"location":"datasets/ned/#public-api","text":"The Open Topo Data public API lets you query NED 10m for free: curl https://api.opentopodata.org/v1/ned10m?locations=37.6535,-119.4105 { \"results\" : [ { \"elevation\" : 3498.298583984375 , \"location\" : { \"lat\" : 37.6535 , \"lng\" : -119.4105 } } ], \"status\" : \"OK\" } NED is still being updated by USGS. The dataset used by the public API was last updated 2020-04-23.","title":"Public API"},{"location":"datasets/nzdem/","text":"NZ DEM The 8m NZ DEM is an interpolation of the 20m contours on the 1:50,000 scale LINZ topo maps . Coverage The datasets covers all of New Zealand except Chatham Island at an 8 metre resolution. NZ DEM elevation rendering. Adding NZ DEM to Open Topo Data mkdir ./data/nzdem8m As of May 2020, the 8m dataset could only be painstaking downloaded a single tile at a time through the LINZ web interface . If you'd rather not do this send me an email , I can send you the raw dataset. Once you've obtained the 115 files, unzip the zip archives and delete anything without a .tif extension. For Open Topo Data to understand the grid arrangement of the files, they need to be renamed to the coordinates of the lower-left corner. Here's the Python script I used, I'm also adding a buffer to help with interpolation near tile borders: import os from glob import glob folder = './data/nzdem8m' # Build vrt for all tifs. pattern = os . path . join ( folder , '*.tif' ) tif_paths = list ( glob ( pattern )) vrt_path = os . path . join ( folder , 'all.vrt' ) assert not os . system ( 'gdalbuildvrt {} {} ' . format ( vrt_path , ' ' . join ( tif_paths ))) buffer_ = 5 for tif_path in tif_paths : with rasterio . open ( tif_path ) as f : new_bounds = ( f . bounds . left - buffer_ * f . res [ 0 ], f . bounds . bottom - buffer_ * f . res [ 1 ], f . bounds . right + buffer_ * f . res [ 0 ], f . bounds . top + buffer_ * f . res [ 1 ], ) new_shape = ( f . shape [ 0 ] + buffer_ * 2 , f . shape [ 1 ] + buffer_ * 2 , ) northing = f . bounds . bottom easting = f . bounds . left filename = 'N {} E {} .tif' . format ( int ( northing ), int ( easting )) buffer_path = os . path . join ( os . path . dirname ( tif_path ), filename ) te = ' ' . join ( str ( x ) for x in new_bounds ) ts = ' ' . join ( str ( x ) for x in new_shape ) cmd = f 'gdalwarp -te {te} -ts {ts} -r near -co NUM_THREADS=ALL_CPUS -co COMPRESS=DEFLATE -co PREDICTOR=3 {vrt_path} {buffer_path} ' assert not os . system ( cmd ) assert not os . system ( f 'rm {vrt_path} ' ) Create a config.yaml file, setting the size of the tiles (65536 metres) and the projection system used ( NZ tranverse mercator ): datasets : - name : nzdem8m path : data/nzdem8m/ filename_tile_size : 65536 filename_epsg : 2193 Rebuild to enable the new dataset at localhost:5000/v1/nzdem8m . make build && make run Public API The Open Topo Data public API lets you query NZ DEM 8m for free: curl https://api.opentopodata.org/v1/nzdem8m?locations=-37.86118,174.79974 { \"results\" : [ { \"elevation\" : 705.4374389648438 , \"location\" : { \"lat\" : -37.86118 , \"lng\" : 174.79974 } } ], \"status\" : \"OK\" } The data files used in the public API were downloaded from LINZ May 2020.","title":"NZ DEM"},{"location":"datasets/nzdem/#nz-dem","text":"The 8m NZ DEM is an interpolation of the 20m contours on the 1:50,000 scale LINZ topo maps .","title":"NZ DEM"},{"location":"datasets/nzdem/#coverage","text":"The datasets covers all of New Zealand except Chatham Island at an 8 metre resolution. NZ DEM elevation rendering.","title":"Coverage"},{"location":"datasets/nzdem/#adding-nz-dem-to-open-topo-data","text":"mkdir ./data/nzdem8m As of May 2020, the 8m dataset could only be painstaking downloaded a single tile at a time through the LINZ web interface . If you'd rather not do this send me an email , I can send you the raw dataset. Once you've obtained the 115 files, unzip the zip archives and delete anything without a .tif extension. For Open Topo Data to understand the grid arrangement of the files, they need to be renamed to the coordinates of the lower-left corner. Here's the Python script I used, I'm also adding a buffer to help with interpolation near tile borders: import os from glob import glob folder = './data/nzdem8m' # Build vrt for all tifs. pattern = os . path . join ( folder , '*.tif' ) tif_paths = list ( glob ( pattern )) vrt_path = os . path . join ( folder , 'all.vrt' ) assert not os . system ( 'gdalbuildvrt {} {} ' . format ( vrt_path , ' ' . join ( tif_paths ))) buffer_ = 5 for tif_path in tif_paths : with rasterio . open ( tif_path ) as f : new_bounds = ( f . bounds . left - buffer_ * f . res [ 0 ], f . bounds . bottom - buffer_ * f . res [ 1 ], f . bounds . right + buffer_ * f . res [ 0 ], f . bounds . top + buffer_ * f . res [ 1 ], ) new_shape = ( f . shape [ 0 ] + buffer_ * 2 , f . shape [ 1 ] + buffer_ * 2 , ) northing = f . bounds . bottom easting = f . bounds . left filename = 'N {} E {} .tif' . format ( int ( northing ), int ( easting )) buffer_path = os . path . join ( os . path . dirname ( tif_path ), filename ) te = ' ' . join ( str ( x ) for x in new_bounds ) ts = ' ' . join ( str ( x ) for x in new_shape ) cmd = f 'gdalwarp -te {te} -ts {ts} -r near -co NUM_THREADS=ALL_CPUS -co COMPRESS=DEFLATE -co PREDICTOR=3 {vrt_path} {buffer_path} ' assert not os . system ( cmd ) assert not os . system ( f 'rm {vrt_path} ' ) Create a config.yaml file, setting the size of the tiles (65536 metres) and the projection system used ( NZ tranverse mercator ): datasets : - name : nzdem8m path : data/nzdem8m/ filename_tile_size : 65536 filename_epsg : 2193 Rebuild to enable the new dataset at localhost:5000/v1/nzdem8m . make build && make run","title":"Adding NZ DEM to Open Topo Data"},{"location":"datasets/nzdem/#public-api","text":"The Open Topo Data public API lets you query NZ DEM 8m for free: curl https://api.opentopodata.org/v1/nzdem8m?locations=-37.86118,174.79974 { \"results\" : [ { \"elevation\" : 705.4374389648438 , \"location\" : { \"lat\" : -37.86118 , \"lng\" : 174.79974 } } ], \"status\" : \"OK\" } The data files used in the public API were downloaded from LINZ May 2020.","title":"Public API"},{"location":"datasets/srtm/","text":"SRTM Overview SRTM is a near-global elevation dataset, with coverage from -60 to 60 degrees latitude. SRTM comes in multiple resolutions. The highest resolution is 1 arc-second, which corresponds to a resolution of about 30m at the equator. The 3 arc-second (90m) version is also frequently used. Coverage SRTM has coverage from -60 to 60 degrees latitude. The dataset is released in 1 degree tiles. Ocean areas covered by a tile have an elevation of 0m. Open Topo Data will return null for locations not covered by a tile. SRTM coverage (green area). Adding 30m SRTM to Open Topo Data Make a new folder for the dataset: mkdir ./data/srtm30m Download the files from USGS into ./data/srtm30m . Before downloading you'll need to register an account at earthdata.nasa.gov . Using these credentials for downloading is a little tricky, but luckily Earthdata provide download scripts in multiple different languages, the Python ones worked well for me. You want the xxxxxxx.SRTMGL1.hgt.zip files. To make downloading a bit easier, here's a list of the 14,297 URLs: srtm30m_urls.txt . Create a config.yaml file: datasets : - name : srtm30m path : data/srtm30m/ Rebuild to enable the new dataset at localhost:5000/v1/srtm30m . make build && make run Extra performance .hgt.zip files are extremely slow for random reads. I got a 10x read speedup and a 10% size reduction from converting to a compressed geotiff: bash gdal_translate -co COMPRESS=DEFLATE -co PREDICTOR=2 {hgtzip_filename} {tif_filename} Adding 90m SRTM to Open Topo Data The process is the same as for 30m. The dataset is hosted on USGS here , and a list of the tile urls is here: srtm90m_urls.txt . Public API The Open Topo Data public API lets you query SRTM 30m for free: curl https://api.opentopodata.org/v1/srtm30m?locations=57.688709,11.976404 { \"results\" : [ { \"elevation\" : 55.0 , \"location\" : { \"lat\" : 57.688709 , \"lng\" : 11.976404 } } ], \"status\" : \"OK\" } as well as SRTM 90m: curl https://api.opentopodata.org/v1/srtm90m?locations=57.688709,11.976404 { \"results\" : [ { \"elevation\" : 55.0 , \"location\" : { \"lat\" : 57.688709 , \"lng\" : 11.976404 } } ], \"status\" : \"OK\" } The public API uses Version 3 of SRTM for both resolutions.","title":"SRTM"},{"location":"datasets/srtm/#srtm","text":"","title":"SRTM"},{"location":"datasets/srtm/#overview","text":"SRTM is a near-global elevation dataset, with coverage from -60 to 60 degrees latitude. SRTM comes in multiple resolutions. The highest resolution is 1 arc-second, which corresponds to a resolution of about 30m at the equator. The 3 arc-second (90m) version is also frequently used.","title":"Overview"},{"location":"datasets/srtm/#coverage","text":"SRTM has coverage from -60 to 60 degrees latitude. The dataset is released in 1 degree tiles. Ocean areas covered by a tile have an elevation of 0m. Open Topo Data will return null for locations not covered by a tile. SRTM coverage (green area).","title":"Coverage"},{"location":"datasets/srtm/#adding-30m-srtm-to-open-topo-data","text":"Make a new folder for the dataset: mkdir ./data/srtm30m Download the files from USGS into ./data/srtm30m . Before downloading you'll need to register an account at earthdata.nasa.gov . Using these credentials for downloading is a little tricky, but luckily Earthdata provide download scripts in multiple different languages, the Python ones worked well for me. You want the xxxxxxx.SRTMGL1.hgt.zip files. To make downloading a bit easier, here's a list of the 14,297 URLs: srtm30m_urls.txt . Create a config.yaml file: datasets : - name : srtm30m path : data/srtm30m/ Rebuild to enable the new dataset at localhost:5000/v1/srtm30m . make build && make run Extra performance .hgt.zip files are extremely slow for random reads. I got a 10x read speedup and a 10% size reduction from converting to a compressed geotiff: bash gdal_translate -co COMPRESS=DEFLATE -co PREDICTOR=2 {hgtzip_filename} {tif_filename}","title":"Adding 30m SRTM to Open Topo Data"},{"location":"datasets/srtm/#adding-90m-srtm-to-open-topo-data","text":"The process is the same as for 30m. The dataset is hosted on USGS here , and a list of the tile urls is here: srtm90m_urls.txt .","title":"Adding 90m SRTM to Open Topo Data"},{"location":"datasets/srtm/#public-api","text":"The Open Topo Data public API lets you query SRTM 30m for free: curl https://api.opentopodata.org/v1/srtm30m?locations=57.688709,11.976404 { \"results\" : [ { \"elevation\" : 55.0 , \"location\" : { \"lat\" : 57.688709 , \"lng\" : 11.976404 } } ], \"status\" : \"OK\" } as well as SRTM 90m: curl https://api.opentopodata.org/v1/srtm90m?locations=57.688709,11.976404 { \"results\" : [ { \"elevation\" : 55.0 , \"location\" : { \"lat\" : 57.688709 , \"lng\" : 11.976404 } } ], \"status\" : \"OK\" } The public API uses Version 3 of SRTM for both resolutions.","title":"Public API"}]}